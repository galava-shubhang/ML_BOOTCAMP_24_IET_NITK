{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧑‍🏫 Task 1 Part 2: Build Your Own Logistic Regression Model for Sentiment Analysis\n",
    "In this exercise, you will build a **logistic regression model** from scratch to perform sentiment analysis.\n",
    "\n",
    "**Objective:** Implement all key components of an ML pipeline (except for data handling).\n",
    "\n",
    "**Allowed Libraries:** `pandas`, `numpy`\n",
    "\n",
    "**Not Allowed:** Any pre-built ML algorithms or functions like `LogisticRegression` from `sklearn`.\n",
    "\n",
    "Follow the instructions step-by-step and answer the questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Data\n",
    "**Task:** Use `pandas` to load the dataset from a file named `IMDB_reviews.csv`.\n",
    "\n",
    "> **Hint:** Use `pd.read_csv()` to load the file and display the first 5 rows.\n",
    "\n",
    "**Question:** What are the key features and the target variable in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and display the first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tokenization and Text Cleaning\n",
    "**Task:** Implement your own function to:\n",
    "1. Convert all text to lowercase.\n",
    "2. Remove punctuation and special characters.\n",
    "3. Split the text into words (tokenization).\n",
    "\n",
    "> **Hint:** Use Python string methods and list comprehensions.\n",
    "\n",
    "**Question:** Why is tokenization important for text-based models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your own tokenizer function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Vocabulary\n",
    "**Task:** Create a **vocabulary** (a list of unique words) from the tokenized dataset.\n",
    "\n",
    "> **Hint:** Use a set to store unique words, then convert it to a list.\n",
    "\n",
    "**Question:** How does vocabulary size affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Implement Word Count\n",
    "**Task:** Calculate and store the number of times each word appears in a particular review for all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Example: Write functions to calculate word counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train-Test Split\n",
    "**Task:** Split the data into **80% training** and **20% testing** sets.\n",
    "\n",
    "> **Hint:** Use `numpy` or list slicing to split the data manually.\n",
    "\n",
    "**Question:** Why do we need to split the data for training and testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Building the Logistic Regression Model (Divided Steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: The Prediction functions\n",
    "The **prediction function** returns the predicted value of the data point using the weights and the bias. It uses the sigmoid function to convert the prediction into a value in the range of 0 to 1.\n",
    "\n",
    "**Task:** Implement the sigmoid and prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    " return\n",
    "\n",
    "def lr_prediction(weights,\tbias,\tfeatures):\n",
    " return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Implementing the Error functions\n",
    "**Task:** Use the gradient update rules to train the logistic regression model over multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def\tlog_loss(weights,\tbias,\tfeatures,\tlabel):\n",
    "    return\n",
    "\n",
    "def\ttotal_log_loss(weights,\tbias,\tX,\ty):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Update Weights\n",
    "The **Update_Weights** adjusts weights and bias based on whether points are correctly or incorrectly classified, It is a simple method of improving the model at every iteration:\n",
    "1. **Correctly classified points:** Move the line **away** from the point.\n",
    "2. **Incorrectly classified points:** Move the line **towards** the point.\n",
    "\n",
    "**Task:** Implement the gradient update function based on these rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Code\n",
    "def\tlr_update_weights(weights,\tbias,\tfeatures,\tlabel,\tlearning_rate\t=\t0.01):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Implementing the Logistic Regression Algorithm\n",
    "**Task:** Use the function to update weights to train the logistic regression model over multiple epochs. Keep track of the total error for each epoch. You will later plot these errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the logistic regression model \n",
    "def\tlr_algorithm(features,\tlabels,\tlearning_rate\t=\t0.01,\tepochs\t=\t200):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate Your Model\n",
    "**Task:** Calculate the accuracy of the model. Compare the predicted labels with the actual labels.\n",
    "\n",
    "> **Hint:** Use the formula for accuracy: (Correct Predictions / Total Predictions) * 100\n",
    "\n",
    "**Question:** Which metric—accuracy, precision, or recall—is most important for sentiment analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize the Errors  \n",
    "**Task:** Create a scatter plot of the total errors over the training epochs. The plot should show a gradual decrease in errors, stabilizing as the model converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Make Predictions on New Data\n",
    "**Task:** Use your trained model to predict the sentiment of the following review:\n",
    "\n",
    "> _\"The movie was absolutely fantastic and kept me hooked till the end.\"_\n",
    "\n",
    "**Question:** What challenges might arise when predicting on new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Wrap-up\n",
    "1. How well did your model perform?\n",
    "2. What challenges did you face while implementing it from scratch?\n",
    "3. What improvements would you suggest for the future?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes (if any):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
